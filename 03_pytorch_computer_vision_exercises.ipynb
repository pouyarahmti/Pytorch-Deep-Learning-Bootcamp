{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pouyarahmti/Pytorch-Deep-Learning-Bootcamp/blob/main/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "2e4ee30b-e956-4112-dc2b-93aa3309b91a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb  1 16:11:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "72af1c66-c045-4f05-965c-185281f4985b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computer Vision Can be used in the following areas:\n",
        "\n",
        "\n",
        "1. Image Classification\n",
        "2. Object Detection\n",
        "3. Image Segmentation"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting means that our model has learnt the patterns in the training data but has not yet generalised to new data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ways to prevent overfitting in machine learning:\n",
        "1. Regularization\n",
        "2. Dropout\n",
        "3. Early stopping"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                        train=True,\n",
        "                                        transform=ToTensor(),\n",
        "                                        target_transform=None,\n",
        "                                        download=True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                        train=False,\n",
        "                                        transform=ToTensor(),\n",
        "                                        download=True)\n",
        "\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2783db95-ab4c-41b6-8095-7f494e6a5a57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iktoV7CDiEkX",
        "outputId": "f6fa3c2b-983c-4071-93c2-5acc941e1b72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  img = train_data[i][0]\n",
        "  label = train_data[i][1]\n",
        "\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "d0f0671a-a190-441b-fedf-4dfb3416ff4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "\n",
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4f1bc9-d6d7-40c8-ba89-7b369a43c545"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}