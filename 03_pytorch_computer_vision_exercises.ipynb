{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "552909d4924246c191a8b7379e18dbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66cf276c6ff3410f9131eb322a441a33",
              "IPY_MODEL_6d6a1f983da44eb5af8be1f7ac89ce12",
              "IPY_MODEL_6a1499bf35f948c5a43d59398a29585e"
            ],
            "layout": "IPY_MODEL_dd6ccc7bbc714eb5bc97dc6499b653d8"
          }
        },
        "66cf276c6ff3410f9131eb322a441a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c408483ca8bb4838863fb55b44b6d3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_7fd7b97e8a3945b7a25f94bb8633706f",
            "value": "100%"
          }
        },
        "6d6a1f983da44eb5af8be1f7ac89ce12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5491107ae3f49ee898510a1295daa8e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48bd8bd14c7c46559bdf1960ed4ccabd",
            "value": 5
          }
        },
        "6a1499bf35f948c5a43d59398a29585e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ecebbd2186a4836aebe1b9d2dc35763",
            "placeholder": "​",
            "style": "IPY_MODEL_ff92fac85be64439ae95a5f6e9b349b5",
            "value": " 5/5 [04:12&lt;00:00, 50.21s/it]"
          }
        },
        "dd6ccc7bbc714eb5bc97dc6499b653d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c408483ca8bb4838863fb55b44b6d3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd7b97e8a3945b7a25f94bb8633706f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5491107ae3f49ee898510a1295daa8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48bd8bd14c7c46559bdf1960ed4ccabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ecebbd2186a4836aebe1b9d2dc35763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff92fac85be64439ae95a5f6e9b349b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pouyarahmti/Pytorch-Deep-Learning-Bootcamp/blob/main/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "91de58fa-857a-41c2-8279-e8d747731c55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "9c1e21f8-52b5-4214-cb20-0669bce25df7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computer Vision Can be used in the following areas:\n",
        "\n",
        "\n",
        "1. Image Classification\n",
        "2. Object Detection\n",
        "3. Image Segmentation"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting means that our model has learnt the patterns in the training data but has not yet generalised to new data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ways to prevent overfitting in machine learning:\n",
        "1. Regularization\n",
        "2. Dropout\n",
        "3. Early stopping"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                        train=True,\n",
        "                                        transform=ToTensor(),\n",
        "                                        target_transform=None,\n",
        "                                        download=True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                        train=False,\n",
        "                                        transform=ToTensor(),\n",
        "                                        download=True)\n",
        "\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012923c0-4fc7-4238-b10e-52b3c4642459"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 37.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.30MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.70MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iktoV7CDiEkX",
        "outputId": "02c96022-899f-4d5a-c625-aff836e83977"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  img = train_data[i][0]\n",
        "  label = train_data[i][1]\n",
        "\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "41709eb1-4e05-4c70-bbdf-7ecf668e045f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAB/CAYAAACQeNq9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHxFJREFUeJzt3XlYlNXiB/DvCDogyKaQeF1SXDA1LRe8huKWuGUY5nLdQIvMUrPIMhfUXDLIJbXcSgzrprnmgtsVM00Lcyk1FUssl6tooaiIwZzfH/4497wwgwzMwsD38zw+z3de3pn3zLy+w+Gc95yjE0IIEBERUZlWzt4FICIiIvtjhYCIiIhYISAiIiJWCIiIiAisEBARERFYISAiIiKwQkBERERghYCIiIjACgERERGhlFYItm/fjmbNmsHFxQU6nQ7p6emIiIjAo48+au+iEZU4xq4XIioenU6HKVOm2LsYZrFJhWDv3r3Q6XRG/x06dMiix7px4wb69u0LV1dXLFq0CAkJCXBzc7PoMUqDrKwsvPXWW6hWrRpcXV0RFBSEXbt22btYZMSMGTOg0+nQuHFji782rxfz3b59GzExMejatSt8fHyg0+kQHx9v72KVaT/++CO6du0KDw8PVKpUCV26dMGxY8fsXSyH42zLg40ePRotW7bUbKtbt65Fj5GcnIyMjAy8++676Ny5s9y+bNkyGAwGix7LkUVERGDt2rV47bXXUK9ePcTHx6N79+5ISkpCcHCwvYtH/+/ixYuYOXOm1X5Jm7peyLTr169j2rRpqFmzJpo2bYq9e/fau0hl2pEjRxAcHIwaNWogJiYGBoMBH330EUJCQvDDDz+gQYMGdilXZmYmnJ1t+iu22Gxa2rZt26JPnz5WPca1a9cAAF5eXprt5cuXt+pxHckPP/yAL7/8ErGxsYiOjgYADBkyBI0bN8a4cePw3Xff2bmEhXfnzp1S/RdtdHQ0WrdujZycHFy/ft3ir2/qerGF7OxsGAwGVKhQwebHLg5/f39cuXIFVatWxeHDh/P9kUO2NWnSJLi6uuLgwYOoXLkyAGDQoEGoX78+3nnnHaxbt84u5XJxcbHLcYvD5vcQZGRkIDs72yqv3b59ewwdOhQA0LJlS+h0OkRERACA5h6Cv//+Gz4+PoiMjMz3Grdu3YKLi4v8RQk8aF6PiYlB3bp1odfrUaNGDYwbNw5ZWVlWeR/WtnbtWjg5OSEqKkpuc3FxwfDhw3Hw4EH88ccfFjlOQV1Fee/nSExMRNu2beHm5oZKlSqhR48eOHnypGafiIgIuLu749dff0X37t1RqVIlDBw4EMCDisEbb7yBGjVqQK/Xo0GDBoiLi4MjL+a5b98+rF27FvPmzbPK6xd0vQDAV199hebNm8PV1RVVqlTBoEGDcOnSpXyv0b59+3yvnfeendTUVOh0OsTFxWHevHkICAiAXq/HqVOnrPHWrEqv16Nq1ao2O97Ro0fRrVs3eHh4wN3dHZ06dcrX1RofHw+dTocDBw7g9ddfh6+vL9zc3NC7d2+kpaXle83CXG+O4ttvv0Xnzp1lZQB4UGkLCQnBli1bcPv2bYsdK/c76NKlSwgLC4O7uzt8fX0RHR2NnJwczb557yGYMmUKdDodzp07h4iICHh5ecHT0xORkZG4e/duvmOtWrVKXn8+Pj7o37+/xb6bTbFpC0FkZCRu374NJycntG3bFrGxsWjRooXFXn/ChAlo0KABli5dimnTpqF27doICAjIt1/58uXRu3dvrF+/HkuWLNH8hbJx40ZkZWWhf//+AACDwYBevXph//79iIqKQsOGDfHzzz9j7ty5OHv2LDZu3Gix8tvK0aNHUb9+fXh4eGi2t2rVCgBw7Ngx1KhRo9jHadiwIRISEjTb0tPT8frrr8PPz09uS0hIwNChQxEaGorZs2fj7t27+PjjjxEcHIyjR49qfrFkZ2cjNDQUwcHBiIuLQ8WKFSGEQK9evZCUlIThw4ejWbNm2LFjB958801cunQJc+fOLfZ7sbWcnByMGjUKL7zwApo0aWKVYxR0vcTHxyMyMhItW7bErFmzcPXqVcyfPx8HDhzA0aNHi9yisGLFCty7dw9RUVHQ6/Xw8fGx4DsqfU6ePIm2bdvCw8MD48aNQ/ny5bFkyRK0b98e33zzDYKCgjT7jxo1Ct7e3oiJiUFqairmzZuHV199FatXr5b7mHO9OYKsrCy4urrm216xYkXcv38fJ06cQOvWrS12vJycHISGhiIoKAhxcXHYvXs3PvjgAwQEBODll19+6PP79u2L2rVrY9asWThy5AiWL18OPz8/zJ49W+4zY8YMTJo0CX379sULL7yAtLQ0LFiwAO3atSvW9fdQwgYOHDggwsPDxSeffCI2bdokZs2aJSpXrixcXFzEkSNHLHqsFStWCAAiOTlZs33o0KGiVq1a8vGOHTsEALF582bNft27dxd16tSRjxMSEkS5cuXEt99+q9lv8eLFAoA4cOCARctvC40aNRIdO3bMt/3kyZMCgFi8eLFVjmswGETPnj2Fu7u7OHnypBBCiIyMDOHl5SVefPFFzb7//e9/haenp2b70KFDBQDx9ttva/bduHGjACCmT5+u2d6nTx+h0+nEuXPnrPJ+rGnhwoXC09NTXLt2TQghREhIiGjUqJHFj2Pserl//77w8/MTjRs3FpmZmXL7li1bBAAxefJkuS0kJESEhITke92819v58+cFAOHh4SHfU2mQnJwsAIgVK1ZY5fXDwsJEhQoVxK+//iq3Xb58WVSqVEm0a9dObss9j507dxYGg0FuHzt2rHBychLp6elCCPOuN0fRpEkTUb9+fZGdnS23ZWVliZo1awoAYu3atRY7Vu530LRp0zTbn3jiCdG8eXPNNgAiJiZGPo6JiREAxLBhwzT79e7dW1SuXFk+Tk1NFU5OTmLGjBma/X7++Wfh7Oycb7sl2aTLoE2bNli7di2GDRuGXr164e2338ahQ4eg0+kwfvx4WxQhn44dO6JKlSqamvNff/2FXbt2oV+/fnLbV199hYYNGyIwMBDXr1+X/zp27AgASEpKsnnZiyszMxN6vT7f9tw+r8zMTKsc991338WWLVsQHx+Pxx57DACwa9cupKenY8CAAZrP18nJCUFBQUY/37y18G3btsHJyQmjR4/WbH/jjTcghEBiYqJV3o+13LhxA5MnT8akSZPg6+tr8+MfPnwY165dw8iRIzX9oD169EBgYCC2bt1a5NcODw+3y3tyRDk5Odi5cyfCwsJQp04dud3f3x//+te/sH//fty6dUvznKioKOh0Ovm4bdu2yMnJwYULFwAU7Xor6UaOHImzZ89i+PDhOHXqFE6cOIEhQ4bgypUrAKzzfTZixAjN47Zt2+K3334r8nNv3Lghz+X69ethMBjQt29fzTmqWrUq6tWrZ9VzZLdbIOvWrYtnn30W69evR05ODpycnIzud/v2bU0fkJOTk0W+UJydnREeHo4vvvgCWVlZ0Ov1WL9+Pf7++29NhSAlJQW//PKLyWPm3pTlSFxdXY3e/3Dv3j35c1OKej62b9+OqVOnYvz48QgPD5fbU1JSAEBWsPLK263h7OyM6tWra7ZduHAB1apVQ6VKlTTbGzZsKH/uSCZOnAgfHx+MGjXK7Oda4nrJ/byM3Z0dGBiI/fv3m12uXLVr1y7yc0uDzMxM3Lx5U7PN1P0IaWlpuHv3rtHz0LBhQxgMBvzxxx9o1KiR3F6zZk3Nft7e3gAe/LEDmH+9OYIRI0bgjz/+QGxsLFauXAkAaNGiBcaNG4cZM2bA3d3d5HOLcr24uLjk28fb21t+xg9T0Dny8PBASkoKhBCoV6+e0edb8wZ5u46JqFGjBu7fv487d+6Y/I8YFxeHqVOnyse1atVCamqqRY7fv39/LFmyBImJiQgLC8OaNWsQGBiIpk2byn0MBgOaNGmCOXPmmHwPjsbf3z/fzWEAZI26WrVqJp9blPNx/vx5DBw4EE8//TSmT5+u+VnuUNCEhASjX4x5h+3o9XqUK1cq59MC8OALe+nSpZg3bx4uX74st9+7dw9///03UlNT4eHhYbLv3ZrXizE6nc7ojZt5b7DKVVBlsyxYvXp1vpuZjX1+RWXqD6vcY5h7vTmKGTNmIDo6GidPnoSnpyeaNGmCd955BwBQv359k88ryvVi6jMurMKcI51Oh8TERKP7FlTBKS67nv3ffvsNLi4uBb7BIUOGaMbFW/ILpV27dvD398fq1asRHByMPXv2YMKECZp9AgICcPz4cXTq1EnTFOfImjVrhqSkJNy6dUtTEfv+++/lz00x93xkZmbiueeeg5eXF/7973/n+2WeexObn59fkcfB16pVC7t370ZGRoamleD06dPy547i0qVLMBgMGD16dL4uEODBX9hjxowxOfLAEtdL7ud15syZfH9JnjlzRvN5ent7G20qdbRWGVsJDQ0t9ARgvr6+qFixIs6cOZPvZ6dPn0a5cuXM/oPEEtdbSeXt7a35v797925Ur14dgYGBJp9jzd8vRRUQEAAhBGrXrl1gZcYabFIhSEtLy9fEcvz4cXz99dfo1q1bgX/x1alTR9N/ZknlypVDnz598Omnn6JVq1bIzs7WdBcAD+4I3bZtG5YtW6YZpgc8+GVnMBgcbhx8nz59EBcXh6VLl8rhlVlZWVixYgWCgoIK/JIx93yMGDECZ8+excGDB2XTmCo0NBQeHh6YOXMmOnTokK85zNj/nby6d++OpUuXYuHChZp7UubOnQudTodu3boVurz21rhxY2zYsCHf9okTJyIjIwPz5883OnImlyWulxYtWsDPzw+LFy/GsGHD5P0miYmJ+OWXXzB58mS5b0BAALZt26Y5T8ePH8eBAwccsvXM2vz9/eHv71+ofZ2cnNClSxds2rQJqamp8u7/q1ev4osvvkBwcLDZTfyWuN4cwerVq5GcnIy4uDi7/X4pqueeew7jx4/H1KlTsWrVKs0fokII/Pnnn5ohlpZkkwpBv3794OrqijZt2sDPzw+nTp3C0qVLUbFiRbz33nu2KEKBZVuwYAFiYmLQpEkT2e+ca/DgwVizZg1GjBiBpKQkPPXUU8jJycHp06exZs0a7Nixw6JDJ20hKCgIzz//PMaPH49r166hbt26WLlyJVJTU/HJJ59Y7Dhbt27FZ599hvDwcPz000/46aef5M/c3d0RFhYGDw8PfPzxxxg8eDCefPJJ9O/fH76+vvj999+xdetWPPXUU1i4cGGBx3nmmWfQoUMHTJgwAampqWjatCl27tyJTZs24bXXXivwF2hJU6VKFYSFheXbntsiYOxnlla+fHnMnj0bkZGRCAkJwYABA+Sww0cffRRjx46V+w4bNgxz5sxBaGgohg8fjmvXrmHx4sVo1KhRvhveSpOFCxciPT1dduts3rwZFy9eBPBg6J+np6dFjjN9+nTs2rULwcHBGDlyJJydnbFkyRJkZWXh/fffN/v1LHG9lTT79u3DtGnT0KVLF1SuXBmHDh3CihUr0LVrV4wZM8bexTNbQEAApk+fjvHjxyM1NRVhYWGoVKkSzp8/jw0bNiAqKkozT45FWW38gmL+/PmiVatWwsfHRzg7Owt/f38xaNAgkZKSYvFjFXbYYS6DwSBq1KhhdNharvv374vZs2eLRo0aCb1eL7y9vUXz5s3F1KlTxc2bNy3+HmwhMzNTREdHi6pVqwq9Xi9atmwptm/fbtFj5J4LY//ynoukpCQRGhoqPD09hYuLiwgICBARERHi8OHDcp+hQ4cKNzc3o8fKyMgQY8eOFdWqVRPly5cX9erVE7GxsZohWI7MlsMOc61evVo88cQTQq/XCx8fHzFw4EBx8eLFfPutWrVK1KlTR1SoUEE0a9ZM7Nixw+Sww9jYWIu/B3uoVauWyf/b58+ft+ixjhw5IkJDQ4W7u7uoWLGi6NChg/juu+80+5g6j0lJSQKASEpKyrf9Ydebozh37pzo0qWLqFKlitDr9SIwMFDMmjVLZGVlWfxYpr6DcocUqmBi2GFaWppmv9xzl/f/zbp160RwcLBwc3MTbm5uIjAwULzyyivizJkzFns/een+v+BERERUhpXe27WJiIio0FghICIiIlYIiIiIiBUCIiIiAisEREREBFYIiIiICGZMTFRapu0taSwx6pPnxjqKe254XqyD10zJxWumZCrseWELAREREbFCQERERKwQEBEREVghICIiIrBCQERERGCFgIiIiMAKAREREYEVAiIiIgIrBERERARWCIiIiAisEBARERHMWMuAyNKaN28u86uvvirzkCFDZP7ss89kXrBggcxHjhyxcumIiMoWthAQERERKwREREQE6EQh10UsictSOjk5yezp6fnQ/dVm6YoVK8rcoEEDmV955RWZ4+LiZB4wYIDmte7duyfze++9J/PUqVMfWg5VWVvKtVmzZjLv2bNHZg8Pj4c+9+bNmzJXrlzZouUyhku5mq9Tp04yf/7555qfhYSEyHzmzJkiH6OsXTPmmjhxoszq91G5cv/7+699+/aa53zzzTcWOTavmZKJyx8TERFRobFCQERERCVrlEHNmjVlrlChgsxt2rSROTg4WGYvLy+Zw8PDi3zcixcvyvzhhx/K3Lt3b5kzMjI0zzl+/LjMlmpuK61atWol87p162RWu3nUJi31s75//77MajdB69atZc474kB9jiNp166dzOp73bBhgz2KUyQtW7aUOTk52Y4lKVsiIiJkfuutt2Q2GAxG97dEtwuVPmwhICIiIlYIiIiIyM5dBuod54D2rvPCjBooDrUpTb0r9/bt2zKrd0lfuXJF8/y//vpL5uLcMV2aqCM3nnzySZlXrVols7+//0NfJyUlReb3339f5i+//FLmAwcOyKyePwCYNWtWIUtcsqh3fterV0/mkt5loN69Xrt2bZlr1aql2Y93kFuP+lm7uLjYsSSlT1BQkMyDBg2SWR0106hRI6PPjY6Olvny5csyq13f6vfj999/X7zCFhNbCIiIiIgVAiIiImKFgIiIiGDnewh+//13zeMbN27IXJx7CNR+mPT0dJk7dOggszo0LSEhocjHov9ZsmSJzHlndjSHev+Bu7u7zOrwTrW//fHHHy/ysUoSdVGngwcP2rEk5lHvC3nxxRdlVvtGAeD06dM2K1NZ0LlzZ5lHjRpldB/1M+/Zs6fMV69etV7BSoF+/frJPH/+fJmrVKkis3pPzN69e2X29fWVOTY21ujrq89V9+/fv3/RCmwhbCEgIiIiVgiIiIjIzl0Gf/75p+bxm2++KbPavHX06FGZ1ZkEVceOHZP56aeflvnOnTsyq0NDxowZY36BKZ/mzZvL3KNHD5lNDTFTm/03b94ss7qQlDo8Rz336lDPjh07PvRYjkYdvudIli9fbnS7OnyULEMdrrZixQqZTXWxqk3WFy5csF7BHJSz8/9+BbZo0ULmZcuWyawOp963b5/M7777rsz79++XWa/Xy7xmzRqZu3TpYrQMhw8fNrfYVuOY30BERERkUawQEBERUcla3Gjjxo0yq7MWqovdNG3aVObhw4fLrDY5q90EqpMnT8ocFRVVrLKWZeoMk7t27ZLZw8NDZnXxlMTERJnV0QfqTF/qbINqE3RaWprM6oJS6kyTalcFoB2lkHfho5JGHSHxyCOP2LEkRWequVr9v0GWMXToUJmrVatmdB/1jvfPPvvM2kVyaOrMg6a6vtT/x+rog1u3bhndX93HVDeBuqDeypUrC1dYG2ALAREREbFCQERERCWsy0Blqjnm5s2bRrerE6KsXr1aZlPrgZN56tevL7M6GkRtLr5+/brM6mJQapOYunjU1q1bjWZzubq6ah6/8cYbMg8cOLDIr2sL3bt3lznv+yjJ1O4NdUEj1aVLl2xVnFJNnQxn2LBhMqvfbeoEbNOnT7dJuRyVOjrgnXfekVnt5vzoo49kVrszTf1eUk2YMOGh+4wePVpmtVvU3thCQERERKwQEBERUQnuMjBlypQpMquT4qh3rKtzfO/cudMm5Spt1Mk1AO0oDrWZWx0Bos7Fr062Yeum8Jo1a9r0eMXRoEEDo9vVETElkfr/Qe0+OHv2rMzq/w0yz6OPPirzunXrHrr/ggULZE5KSrJGkRzW5MmTNY/VbgJ1TZsdO3bI/NZbb8mcmZlp9HVdXFxkVkcTqN8/6qRpalfOpk2bClV2W2MLAREREbFCQERERA7YZaBOOqSOLFAnoFHnoVabz9Rm7EWLFsms3l1KDzzxxBOax2o3gerZZ5+VWV2ngIonOTnZbsdWJ5jq2rWrzOokLqYmXFHv4FbvfCfzqJ+7qeW9//Of/8isLtFLgJeXl8wjR47U/Ez9vle7CcLCwh76unXr1pX5888/l1ntvlatXbtW5vfff/+hr29vbCEgIiIiVgiIiIjIAbsMVL/++qvMERERMqvLgg4ePNhodnNzk1md71udUKcsmzNnjuaxeres2jVgr24Cdang0jj5lI+Pj9nPUdf5UM+XOuqmevXqMleoUEFmdQIn9bNV77D+/vvvZc7KypJZXUL2xx9/NLvc9IDaZP3ee+8Z3UddZldd18DUhG1llfp/W53YKS91giA/Pz+ZIyMjZe7Vq5fMjRs3ltnd3V1mtRtCzatWrZLZ1Bo7JQlbCIiIiIgVAiIiInLwLgPVhg0bZE5JSZFZbfru1KmTzDNnzpS5Vq1aMs+YMUPmsjYXe8+ePWVWlzgGtM1gX3/9ta2KZJLaTZB3lMixY8dsXJqiU5vk1fexePFimdWJVAqi3o2udhlkZ2fLfPfuXZlPnTol86effiqzOhpH7RK6evWqzOryrerEU6dPny5UWekBcycg+u2332RWzwdpqRMO5V0rwNfXV+bz58/LXJjRZpcvX5ZZXdfA399fZnVNl82bNxeyxCUDWwiIiIiIFQIiIiIqRV0GqhMnTsjct29fmZ955hmZ1ZEIL730ksz16tWT+emnn7ZWEUsktelXvUsXAK5duyazury0talrKqjrWKj27NmjeTx+/HhrFsmi1ElTLly4IHObNm3Mfq3ff/9d5o0bN8r8yy+/yHzo0CGzXzdXVFSUzGqzq9qMTeZR58wvzGgZU6MPSEudFCvvhENbtmyRWR3No45aU9caiI+Pl/nPP/+U+csvv5RZ7TJQtzsathAQERERKwRERERUSrsMVGrTUUJCgszLly+XWZ1YpV27djK3b99e5r1791qlfI5CnYjG2pM3qd0EEydOlPnNN9+UWb3L/YMPPtA8//bt21YsnfXMnj3b3kUokDpKR1WYu+Ppf9QRPKbWhFCpzddnzpyxRpFKNXVCLUDb3WUu9fdDSEiIzGp3jyN3obGFgIiIiFghICIiolLaZaBO0NKnTx+ZW7ZsKbPaTaBSJ2vZt2+fFUrnmKw9GZHajKp2DfTr109mtek0PDzcquWhwlMnBaOH27lzp8ze3t5G91FHg6jrtJB9qSOxTE2OxlEGRERE5NBYISAiIiLH7jJo0KCBzK+++qrMzz33nMxVq1Z96Ovk5OTIrN5BXxqX1S2IOv+9mgHt5B5jxoyxyPHGjh0r86RJk2T29PSU+fPPP5d5yJAhFjkukT1VrlxZZlPfMR999JHMjjpqpjTasWOHvYtgVWwhICIiIlYIiIiIyEG6DNRm/wEDBsisdhOoy4gWhrrEq7rkcUlY2tde1Dtl8y4Fqp6DDz/8UGZ12dwbN27I3Lp1a5kHDx4sc9OmTWWuXr26zOo8/GqznNp0SiWH2qVUv359mYuzVkJppq6dUq7cw/8O++6776xZHCqi0NBQexfBqthCQERERKwQEBERUQnrMnjkkUdkfuyxx2ReuHChzIGBgWa9pjqPdWxsrMzqJDdlbTRBUTg5OcmsLtmrThB069YtmdVlpE1Rm0WTkpJknjx5cpHLSbahdikVpgm8LFIn2+rcubPM6vfN/fv3ZV60aJHMV69etW7hqEjq1Klj7yJYFa9kIiIiYoWAiIiIWCEgIiIi2OEeAh8fH5mXLFmi+Zna52ZuX43aH/3BBx/IrA5hy8zMNOs1y5qDBw/KnJycrPmZujCUSh2OqN4DolKHI6oLf1hqxkOyr3/+858yx8fH268gJYyXl5fMpmZMvXTpkszR0dHWLhIV07fffiuzeu9MabkPjS0ERERExAoBERERWbHLICgoSGZ1fftWrVrJ/I9//MPs1717967M6ox5M2fOlPnOnTtmvy4BFy9elFldIAoAXnrpJZknTpz40NeaP3++zB9//LHM586dK04RqYTIu/gVUVlw4sQJmVNSUmRWu7gDAgJkTktLs03BLIQtBERERMQKAREREVmxy6B3795Gc0FOnTol85YtW2TOzs6WWR1BkJ6eXowSUkGuXLmieTxlyhSjmcqOxMREmZ9//nk7lsQxnD59WmZ1FFRwcLA9ikMWpnZTL1++XGZ1sbxRo0bJrP5+K6nYQkBERESsEBARERGgE3kXvje1I+8qtopCfvwF4rmxjuKeG54X6+A1U3KVpWvGw8ND5jVr1sisLmS1fv16mSMjI2W29Ui4wp4XthAQERERKwRERETELgO7Y/NnyVWWmj8dCa+ZkqusXjNq94E6yuDll1+W+fHHH5fZ1iMO2GVAREREhcYKAREREbHLwN7Y/FlyldXmz5KO10zJxWumZGKXARERERUaKwRERERU+C4DIiIiKr3YQkBERESsEBARERErBERERARWCIiIiAisEBARERFYISAiIiKwQkBERERghYCIiIjACgEREREB+D88KMWCNNd+IAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "\n",
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18850c8a-8291-427d-b55a-8d38ad5002f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model_cpu = TinyVGG(input_shape=1,\n",
        "                    hidden_units=10,\n",
        "                    output_shape=len(class_names)).to(\"cpu\")\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_cpu.parameters(), lr=0.1)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Start measuring time\n",
        "start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model_cpu(X)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Evaluation loop\n",
        "    test_loss = 0\n",
        "    model_cpu.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
        "            X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\n",
        "            y_test_pred = model_cpu(X_test)\n",
        "            loss = loss_fn(y_test_pred, y_test)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f}\")\n",
        "\n",
        "# End measuring time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate total time taken\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total training time: {total_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD",
        "outputId": "4135f36f-4d55-4213-8b04-a6e5fe7a77fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "552909d4924246c191a8b7379e18dbb8",
            "66cf276c6ff3410f9131eb322a441a33",
            "6d6a1f983da44eb5af8be1f7ac89ce12",
            "6a1499bf35f948c5a43d59398a29585e",
            "dd6ccc7bbc714eb5bc97dc6499b653d8",
            "c408483ca8bb4838863fb55b44b6d3c4",
            "7fd7b97e8a3945b7a25f94bb8633706f",
            "d5491107ae3f49ee898510a1295daa8e",
            "48bd8bd14c7c46559bdf1960ed4ccabd",
            "8ecebbd2186a4836aebe1b9d2dc35763",
            "ff92fac85be64439ae95a5f6e9b349b5"
          ]
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "552909d4924246c191a8b7379e18dbb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.64354 | Test loss: 0.11831\n",
            "Epoch: 1 | Train loss: 0.09933 | Test loss: 0.08739\n",
            "Epoch: 2 | Train loss: 0.07414 | Test loss: 0.05423\n",
            "Epoch: 3 | Train loss: 0.06072 | Test loss: 0.05694\n",
            "Epoch: 4 | Train loss: 0.05333 | Test loss: 0.09860\n",
            "Total training time: 252.53 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}